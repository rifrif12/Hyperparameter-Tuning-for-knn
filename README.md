# Hyperparameter-Tuning-for-knn
k-nearest neighbors algorithm (k-NN) is a non-parametric classification method first developed by Evelyn Fix and Joseph Hodges in 1951,[1] and later expanded by Thomas Cover.[2] It is used for classification and regression. k-NN is supervised learning so it's need k optimum to get the best accuracy

tuning hyperparemter is a method to get k optimum

data from National Institute of Diabetes and Digestive and Kidney Diseases; Includes cost data (donated by Peter Turney)
Requirement: Google Colaboratory
#KNN #MachineLearning #Python #Hyperparameter
